{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIMA Model Evaluation\n",
    "This notebook evaluates image quality using the Neural Image Assessment (NIMA) model. \n",
    "It computes technical and aesthetic scores for a set of images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install tensorflow\n",
    "!pip install pillow\n",
    "!pip install pandas\n",
    "!git clone https://github.com/idealo/image-quality-assessment.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Create __init__.py in the evaluater and handlers folders\n",
    "open('image-quality-assessment/src/evaluater/__init__.py', 'a').close()\n",
    "open('image-quality-assessment/src/handlers/__init__.py', 'a').close()\n",
    "open('image-quality-assessment/src/utils/__init__.py', 'a').close()\n",
    "\n",
    "sys.path.append('image-quality-assessment/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from utils.utils import calc_mean_score, save_json\n",
    "from handlers.model_builder import Nima\n",
    "from handlers.data_generator import TestDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images from Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_dir_to_json(img_dir, img_type='jpg'):\n",
    "    \"\"\"\n",
    "    Convert images in a directory to a JSON format.\n",
    "\n",
    "    Args:\n",
    "        img_dir (str): The directory path where the images are located.\n",
    "        img_type (str, optional): The image file extension. Defaults to 'jpg'.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary represents an image with its ID.\n",
    "\n",
    "    \"\"\"\n",
    "    img_paths = glob.glob(os.path.join(img_dir, '*.'+img_type))\n",
    "\n",
    "    samples = []\n",
    "    for img_path in img_paths:\n",
    "        img_id = os.path.basename(img_path).split('.')[0]\n",
    "        samples.append({'image_id': img_id})\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function converts all the images in the image directory to jpg and saves them in a new directory\n",
    "def convert_images(image_dir,output_dir):\n",
    "    \"\"\"\n",
    "    Convert images in a directory to PNG format.\n",
    "\n",
    "    Args:\n",
    "        image_dir (str): The directory path where the images are located.\n",
    "\n",
    "    \"\"\"\n",
    "    img_paths = glob.glob(os.path.join(image_dir, '*'))\n",
    "\n",
    "    for img_path in img_paths:\n",
    "        try:\n",
    "            img_id = os.path.basename(img_path).split('.')[0]\n",
    "            img = Image.open(img_path)\n",
    "            img.save(os.path.join(output_dir, img_id+'.png'))\n",
    "        except:\n",
    "            print(f'Error converting {img_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Images to PNG, if neccessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting /Volumes/tus6/b50/Hiwis/04_Leo/Amelie_Meta_Pictures/Thumbs.db\n"
     ]
    }
   ],
   "source": [
    "image_dir = # TODO change this to the path of the images you want to evaluate\n",
    "output_dir = # TODO change this to the path where you want to save the converted images\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "convert_images(image_dir,output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = #TODO change this to the path where the converted images are saved\n",
    "\n",
    "samples = image_dir_to_json(input_dir, 'png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model Weights and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model and load weights\n",
    "nima = Nima('MobileNet', weights=None)\n",
    "nima.build()\n",
    "data_generator = TestDataGenerator(samples, input_dir, 64, 10, nima.preprocessing_function(),img_format='png')\n",
    "\n",
    "weigths_file_technical = 'image-quality-assessment/models/MobileNet/weights_mobilenet_technical_0.11.hdf5'\n",
    "weigths_file_aesthetic = 'image-quality-assessment/models/MobileNet/weights_mobilenet_aesthetic_0.07.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonardkinzinger/Desktop/NIMA/.venv/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 935ms/stepWARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x2d4664ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 673ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 564ms/step\n"
     ]
    }
   ],
   "source": [
    "technical=True\n",
    "aesthetic=True\n",
    "\n",
    "if technical:\n",
    "    nima.nima_model.load_weights(weigths_file_technical)\n",
    "\n",
    "    predictions = nima.nima_model.predict(\n",
    "        data_generator,\n",
    "        batch_size=10,\n",
    "        verbose=1)\n",
    "    \n",
    "    # calc mean scores and add to samples\n",
    "    for i, sample in enumerate(samples):\n",
    "        sample['nima_technical'] = calc_mean_score(predictions[i])\n",
    "\n",
    "if aesthetic:\n",
    "    nima.nima_model.load_weights(weigths_file_aesthetic)\n",
    "\n",
    "    predictions = nima.nima_model.predict(\n",
    "        data_generator,\n",
    "        batch_size=10,\n",
    "        verbose=1)\n",
    "    \n",
    "    # calc mean scores and add to samples\n",
    "    for i, sample in enumerate(samples):\n",
    "        sample['nima_aesthetic'] = calc_mean_score(predictions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results as a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>nima_technical</th>\n",
       "      <th>nima_aesthetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214_Choi_02_human_woman_full_color</td>\n",
       "      <td>4.539200</td>\n",
       "      <td>5.429706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142_Wan_and_Jiang_01_a_virtual_woman_fullbody_...</td>\n",
       "      <td>5.274675</td>\n",
       "      <td>4.360690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121_Nissen_20_human_woman_upperbody_bw</td>\n",
       "      <td>5.214574</td>\n",
       "      <td>4.584579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151_Yang_01_a_human_woman_faceshot_color</td>\n",
       "      <td>5.999182</td>\n",
       "      <td>4.206086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121_Nissen_08_virtual_woman_fullbody_bw</td>\n",
       "      <td>5.719997</td>\n",
       "      <td>5.174316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>53_Ozdemir_02_a_virtual_woman_upperbody_color</td>\n",
       "      <td>5.660220</td>\n",
       "      <td>5.461650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>31_Stein_01_b_virtual_woman_fullstimuli_color</td>\n",
       "      <td>5.554849</td>\n",
       "      <td>5.102993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>92_Li_01_human_woman_fullprofile_color</td>\n",
       "      <td>4.558420</td>\n",
       "      <td>4.242528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>142_Wan_and_Jiang_06_b_human_woman_fullbody_color</td>\n",
       "      <td>4.929629</td>\n",
       "      <td>4.630395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>303_Sands_01_b_virtual_woman_fullstimuli_color</td>\n",
       "      <td>4.043926</td>\n",
       "      <td>4.502575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  nima_technical  \\\n",
       "0                   214_Choi_02_human_woman_full_color        4.539200   \n",
       "1    142_Wan_and_Jiang_01_a_virtual_woman_fullbody_...        5.274675   \n",
       "2               121_Nissen_20_human_woman_upperbody_bw        5.214574   \n",
       "3             151_Yang_01_a_human_woman_faceshot_color        5.999182   \n",
       "4              121_Nissen_08_virtual_woman_fullbody_bw        5.719997   \n",
       "..                                                 ...             ...   \n",
       "149      53_Ozdemir_02_a_virtual_woman_upperbody_color        5.660220   \n",
       "150      31_Stein_01_b_virtual_woman_fullstimuli_color        5.554849   \n",
       "151             92_Li_01_human_woman_fullprofile_color        4.558420   \n",
       "152  142_Wan_and_Jiang_06_b_human_woman_fullbody_color        4.929629   \n",
       "153     303_Sands_01_b_virtual_woman_fullstimuli_color        4.043926   \n",
       "\n",
       "     nima_aesthetic  \n",
       "0          5.429706  \n",
       "1          4.360690  \n",
       "2          4.584579  \n",
       "3          4.206086  \n",
       "4          5.174316  \n",
       "..              ...  \n",
       "149        5.461650  \n",
       "150        5.102993  \n",
       "151        4.242528  \n",
       "152        4.630395  \n",
       "153        4.502575  \n",
       "\n",
       "[154 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(samples)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = #TODO change this to the path where you want to save the output csv file\n",
    "df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
